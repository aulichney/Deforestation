{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/project/sanford/asu5/conda_envs/deforest/lib/python3.11/site-packages/shap/utils/_clustering.py:34: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit\n",
      "/gpfs/gibbs/project/sanford/asu5/conda_envs/deforest/lib/python3.11/site-packages/shap/utils/_clustering.py:53: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit\n",
      "/gpfs/gibbs/project/sanford/asu5/conda_envs/deforest/lib/python3.11/site-packages/shap/utils/_clustering.py:62: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit\n",
      "/gpfs/gibbs/project/sanford/asu5/conda_envs/deforest/lib/python3.11/site-packages/shap/utils/_clustering.py:68: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit\n",
      "/gpfs/gibbs/project/sanford/asu5/conda_envs/deforest/lib/python3.11/site-packages/shap/utils/_clustering.py:76: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit\n",
      "/gpfs/gibbs/project/sanford/asu5/conda_envs/deforest/lib/python3.11/site-packages/shap/links.py:4: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit\n",
      "/gpfs/gibbs/project/sanford/asu5/conda_envs/deforest/lib/python3.11/site-packages/shap/links.py:9: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit\n",
      "/gpfs/gibbs/project/sanford/asu5/conda_envs/deforest/lib/python3.11/site-packages/shap/links.py:14: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit\n",
      "/gpfs/gibbs/project/sanford/asu5/conda_envs/deforest/lib/python3.11/site-packages/shap/links.py:19: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit\n",
      "/gpfs/gibbs/project/sanford/asu5/conda_envs/deforest/lib/python3.11/site-packages/shap/utils/_masked_model.py:362: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit # we can't use this when using a custom link function...\n",
      "/gpfs/gibbs/project/sanford/asu5/conda_envs/deforest/lib/python3.11/site-packages/shap/utils/_masked_model.py:384: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit\n",
      "/gpfs/gibbs/project/sanford/asu5/conda_envs/deforest/lib/python3.11/site-packages/shap/utils/_masked_model.py:427: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit\n",
      "/gpfs/gibbs/project/sanford/asu5/conda_envs/deforest/lib/python3.11/site-packages/shap/utils/_masked_model.py:438: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit\n",
      "/gpfs/gibbs/project/sanford/asu5/conda_envs/deforest/lib/python3.11/site-packages/shap/maskers/_tabular.py:185: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit\n",
      "/gpfs/gibbs/project/sanford/asu5/conda_envs/deforest/lib/python3.11/site-packages/shap/maskers/_tabular.py:196: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit\n",
      "/gpfs/gibbs/project/sanford/asu5/conda_envs/deforest/lib/python3.11/site-packages/shap/maskers/_image.py:174: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit\n",
      "/gpfs/gibbs/project/sanford/asu5/conda_envs/deforest/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/gpfs/gibbs/project/sanford/asu5/conda_envs/deforest/lib/python3.11/site-packages/shap/explainers/_partition.py:675: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import pyreadr\n",
    "from scipy.spatial import distance\n",
    "from tqdm import tqdm\n",
    "\n",
    "#import shapefile as shp  # Requires the pyshp package\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, cross_val_predict\n",
    "import geopandas as gpd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import shap\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2004 2005 2006 2007]\n",
      "(665048, 216)\n",
      "Test set pct of data: 30.0\n",
      "New test/train indices generated and read in\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [01:37<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2007]\n",
      "[2004 2005 2006]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 2) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 250\u001b[0m\n\u001b[1;32m    247\u001b[0m     train_indices, test_indices \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlist\u001b[39m(traintest) \u001b[38;5;28;01mfor\u001b[39;00m traintest \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mmuni_kfold)]\n\u001b[1;32m    248\u001b[0m     muni_cv \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mzip\u001b[39m(train_indices,test_indices)]\n\u001b[0;32m--> 250\u001b[0m     \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFeatureImportanceResults/muni_cv.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmuni_cv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNew test/train indices generated and read in\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m NEW_CV_INDICES:\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36msave\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/gpfs/gibbs/project/sanford/asu5/conda_envs/deforest/lib/python3.11/site-packages/numpy/lib/npyio.py:521\u001b[0m, in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    518\u001b[0m     file_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[0;32m--> 521\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_array(fid, arr, allow_pickle\u001b[38;5;241m=\u001b[39mallow_pickle,\n\u001b[1;32m    523\u001b[0m                        pickle_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(fix_imports\u001b[38;5;241m=\u001b[39mfix_imports))\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 2) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "\n",
    "first_time = True\n",
    "\n",
    "for this_start_year in tqdm([2004]):\n",
    "    SUBSET = True\n",
    "    SUBSET_SIZE = 100\n",
    "\n",
    "    if first_time: \n",
    "        NEW_INDICES = True\n",
    "        NEW_CV_INDICES = True\n",
    "        first_time = False\n",
    "    else: \n",
    "        NEW_INDICES = False\n",
    "        NEW_CV_INDICES = False\n",
    "\n",
    "    PLOT_ENTIRE_AREA = True\n",
    "    PLOT_FOLDS = False\n",
    "\n",
    "    START_YEAR_TRAIN = this_start_year\n",
    "    NUMBER_YEARS_TRAIN = 3\n",
    "    YEARS_TO_TRAIN = [START_YEAR_TRAIN + i  for i in range(NUMBER_YEARS_TRAIN + 1)]\n",
    "\n",
    "    PREDICT_YEAR = START_YEAR_TRAIN + NUMBER_YEARS_TRAIN\n",
    "\n",
    "    FOLDER_NAME = ''.join([f'{START_YEAR_TRAIN + i}_' for i in list(range(NUMBER_YEARS_TRAIN))]) + f'PREDICT_{PREDICT_YEAR}'\n",
    "\n",
    "\n",
    "    FILE_PATH = f'FeatureImportanceResults/{FOLDER_NAME}/'\n",
    "\n",
    "    if not os.path.exists(f'FeatureImportanceResults/{FOLDER_NAME}'):\n",
    "        os.makedirs(f'FeatureImportanceResults/{FOLDER_NAME}')\n",
    "        \n",
    "        \n",
    "    df_full = pd.read_csv(f'FinalData/FinalData{START_YEAR_TRAIN}_1.csv')\n",
    "    df_full = pd.concat([df_full, pd.read_csv(f'FinalData/FinalData{START_YEAR_TRAIN}_2.csv')])\n",
    "    df_full = pd.concat([df_full, pd.read_csv(f'FinalData/FinalData{START_YEAR_TRAIN}_3.csv')])\n",
    "    df_full = pd.concat([df_full, pd.read_csv(f'FinalData/FinalData{START_YEAR_TRAIN}_4.csv')])\n",
    "\n",
    "\n",
    "    for year in YEARS_TO_TRAIN[1:]:\n",
    "        filename = f'FinalData/FinalData{str(year)}_1.csv'\n",
    "        df_full = pd.concat([df_full, pd.read_csv(filename)])\n",
    "        filename = f'FinalData/FinalData{str(year)}_2.csv'\n",
    "        df_full = pd.concat([df_full, pd.read_csv(filename)])\n",
    "        filename = f'FinalData/FinalData{str(year)}_3.csv'\n",
    "        df_full = pd.concat([df_full, pd.read_csv(filename)])\n",
    "        filename = f'FinalData/FinalData{str(year)}_4.csv'\n",
    "        df_full = pd.concat([df_full, pd.read_csv(filename)])\n",
    "\n",
    "    print(np.unique(df_full.year))\n",
    "    print(df_full.shape)\n",
    "\n",
    "\n",
    "    X_cols  = ['year', 'rain1', 'elevation', 'slope', 'aspect', 'near_mines',\n",
    "        'near_roads', 'near_hidrovia', 'indigenous_homol',\n",
    "        'mun_election_year', 'new_forest_code', 'lula', 'dilma', 'temer',\n",
    "        'bolsonaro', 'fed_election_year', 'populacao', 'pib_pc', 'ironore',\n",
    "        'silver', 'copper', 'gold', 'soy_price', 'beef_price', 'ag_jobs',\n",
    "        'mining_jobs', 'public_jobs', 'construction_jobs', 'PIB',\n",
    "        'n_companies_PUBLIC ADMIN', 'n_companies_AGRICULTURE',\n",
    "        'n_companies_FOOD AND DRINKS', 'n_companies_ACCOMODATION AND FOOD',\n",
    "        'n_companies_EQUIPMENT RENTAL', 'n_companies_WHOLESALE',\n",
    "        'n_companies_ASSOCIATIVE ACTIVITIES',\n",
    "        'n_companies_AUTOMOBILES AND TRANSPORT',\n",
    "        'n_companies_FINANCIAL ASSISTANCE',\n",
    "        'n_companies_TRADE REP VEHICLES', 'n_companies_CONSTRUCTION',\n",
    "        'n_companies_MAIL AND TELECOM', 'n_companies_CULTURE AND SPORT',\n",
    "        'n_companies_EDITING AND PRINTING', 'n_companies_EDUCATION',\n",
    "        'n_companies_ELECTRICITY AND GAS', 'n_companies_FINANCES',\n",
    "        'n_companies_CLEANING AND SEWAGE', 'n_companies_MACHINERY',\n",
    "        'n_companies_BASIC METALLURGY', 'n_companies_MINING',\n",
    "        'n_companies_WOOD PROD',\n",
    "        'n_companies_NON-METALLIC MINERAL PRODUCTS', 'n_companies_HEALTH',\n",
    "        'n_companies_SERVICES FOR COMPANIES',\n",
    "        'n_companies_PERSONAL SERVICES', 'n_companies_TRANSPORTATION',\n",
    "        'n_companies_GROUND TRANSPORT',\n",
    "        'n_companies_WATER TREATMENT AND DISTRIBUTION',\n",
    "        'n_companies_RETAIL', 'n_companies_COMPUTING',\n",
    "        'n_companies_INSURANCE AND SOCIAL SECURITY',\n",
    "        'n_companies_METALLIC PRODUCTS', 'n_companies_DOMESTIC SERVICES',\n",
    "        'n_companies_FORESTRY', 'n_companies_CLOTHING',\n",
    "        'n_companies_PAPER', 'n_companies_INTERNATIONAL BODIES',\n",
    "        'n_companies_OIL AND GAS', 'n_companies_FISHING AND AQUACULTURE',\n",
    "        'n_companies_CHEMICALS', 'n_companies_WATER-BASED TRANSPORTATION',\n",
    "        'n_companies_REAL ESTATE', 'n_companies_RECYCLING',\n",
    "        'n_companies_LEATHERS AND FOOTWEAR',\n",
    "        'n_companies_RUBBER AND PLASTIC', 'n_companies_TEXTILES',\n",
    "        'n_companies_RESEARCH AND DEVELOPMENT',\n",
    "        'n_companies_AERO TRANSPORT', 'n_companies_SMOKE',\n",
    "        'n_companies_PETROLEUM REFINING', 'n_companies_',\n",
    "        'n_jobs_PUBLIC ADMIN', 'n_jobs_AGRICULTURE',\n",
    "        'n_jobs_FOOD AND DRINKS', 'n_jobs_ACCOMODATION AND FOOD',\n",
    "        'n_jobs_EQUIPMENT RENTAL', 'n_jobs_WHOLESALE',\n",
    "        'n_jobs_ASSOCIATIVE ACTIVITIES',\n",
    "        'n_jobs_AUTOMOBILES AND TRANSPORT', 'n_jobs_FINANCIAL ASSISTANCE',\n",
    "        'n_jobs_TRADE REP VEHICLES', 'n_jobs_CONSTRUCTION',\n",
    "        'n_jobs_MAIL AND TELECOM', 'n_jobs_CULTURE AND SPORT',\n",
    "        'n_jobs_EDITING AND PRINTING', 'n_jobs_EDUCATION',\n",
    "        'n_jobs_ELECTRICITY AND GAS', 'n_jobs_FINANCES',\n",
    "        'n_jobs_CLEANING AND SEWAGE', 'n_jobs_MACHINERY',\n",
    "        'n_jobs_BASIC METALLURGY', 'n_jobs_MINING', 'n_jobs_WOOD PROD',\n",
    "        'n_jobs_NON-METALLIC MINERAL PRODUCTS', 'n_jobs_HEALTH',\n",
    "        'n_jobs_SERVICES FOR COMPANIES', 'n_jobs_PERSONAL SERVICES',\n",
    "        'n_jobs_TRANSPORTATION', 'n_jobs_GROUND TRANSPORT',\n",
    "        'n_jobs_WATER TREATMENT AND DISTRIBUTION', 'n_jobs_RETAIL',\n",
    "        'n_jobs_COMPUTING', 'n_jobs_INSURANCE AND SOCIAL SECURITY',\n",
    "        'n_jobs_METALLIC PRODUCTS', 'n_jobs_DOMESTIC SERVICES',\n",
    "        'n_jobs_FORESTRY', 'n_jobs_CLOTHING', 'n_jobs_PAPER',\n",
    "        'n_jobs_INTERNATIONAL BODIES', 'n_jobs_OIL AND GAS',\n",
    "        'n_jobs_FISHING AND AQUACULTURE', 'n_jobs_CHEMICALS',\n",
    "        'n_jobs_WATER-BASED TRANSPORTATION', 'n_jobs_REAL ESTATE',\n",
    "        'n_jobs_RECYCLING', 'n_jobs_LEATHERS AND FOOTWEAR',\n",
    "        'n_jobs_RUBBER AND PLASTIC', 'n_jobs_TEXTILES',\n",
    "        'n_jobs_RESEARCH AND DEVELOPMENT', 'n_jobs_AERO TRANSPORT',\n",
    "        'n_jobs_SMOKE', 'n_jobs_PETROLEUM REFINING', 'n_jobs_',\n",
    "        'n_jobs_TOTAL INDUSTRIAL', 'n_jobs_TOTAL SERVICE',\n",
    "        'n_companies_TOTAL INDUSTRIAL', 'n_companies_TOTAL SERVICE',\n",
    "        'n_companies_TOTAL', 'n_jobs_TOTAL', 'murder_threats',\n",
    "        'assassination', 'assassination_attempt', 'f_emitted_count',\n",
    "        'expen_agri', 'expen_env_man', 'expen_agr_org', 'expen_mining',\n",
    "        'expen_petrol', 'expen_prom_ani_pro', 'expen_prom_veg_pro',\n",
    "        'expen_other_agr', 'expen_agr_defense', 'expen_min_fuel',\n",
    "        'illegal_mining', 'illegal_other', 'illegal_industry', 'audits',\n",
    "        'emiss_pec_full', 'emiss_agr_full', 'emiss_agropec_full',\n",
    "        'incumbant', 'term_limited_seat', 'special',\n",
    "        'overall_winner_complete_college', \n",
    "        'overall_winner_feminino', 'overall_winner_agriculture_job',\n",
    "        'overall_winner_public_service_job', 'overall_winner_health_job',\n",
    "        'overall_winner_corporate_job', 'overall_winner_law_job',\n",
    "        'overall_winner_technical_job', 'overall_winner_professional_job',\n",
    "        'overall_winner_mining_job', 'overall_winner_partido_PT',\n",
    "        'overall_winner_partido_PMDB_MDB', 'overall_winner_partido_PSDB',\n",
    "        'overall_winner_partido_DEM', 'overall_winner_partido_PL',\n",
    "        'overall_winner_partido_other', 'runnerup_partido_PT',\n",
    "        'runnerup_partido_PMDB_MDB', 'runnerup_partido_PSDB',\n",
    "        'runnerup_partido_DEM', 'runnerup_partido_PL',\n",
    "        'runnerup_partido_other', 'winner_votes_proportion',\n",
    "        'vote_participation_proportion',\n",
    "        'forest_formation', 'savanna', 'mangrove', 'silvicultura',\n",
    "        'pasture', 'sugarcane', 'mosaic_ag', 'urban', 'mining', 'water',\n",
    "        'soybean', 'rice', 'other_crop', 'coffee', 'citrus',\n",
    "        'other_perennial', 'forest_lag']\n",
    "\n",
    "\n",
    "    #'runnerup_votes_proportion', \n",
    "    #'overall_winner_idade',\n",
    "\n",
    "\n",
    "    ## Test train split\n",
    "    #split into two groups where no muni in train set is tested\n",
    "    #then do a second split by year so that the train years are year n, n+1, n+2 and the test set uses n+3.\n",
    "    if SUBSET:\n",
    "        df_full = df_full.sample(SUBSET_SIZE).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    Y = df_full['forest_diff']\n",
    "    X = df_full[X_cols]\n",
    "    # gdf = gpd.GeoDataFrame(X, geometry = gpd.points_from_xy(df_full.x, df_full.y))\n",
    "    # XYs = gdf['geometry']\n",
    "\n",
    "\n",
    "    if NEW_INDICES:\n",
    "\n",
    "        #Select Test/Train Indices\n",
    "        n_folds = 10 \n",
    "        munis = df_full['ID'].values\n",
    "        group_kfold = GroupKFold(n_splits = n_folds)\n",
    "        muni_kfold = group_kfold.split(X, Y, munis) \n",
    "        train_indices, test_indices = [list(traintest) for traintest in zip(*muni_kfold)]\n",
    "        city_cv = [*zip(train_indices,test_indices)]\n",
    "\n",
    "        test_inds = []\n",
    "        for i in range(3):\n",
    "            test_inds.extend(city_cv[i][1])\n",
    "\n",
    "        train_inds = []\n",
    "        for i in range(3, 10):\n",
    "            train_inds.extend(city_cv[i][1])\n",
    "\n",
    "        print(f'Test set pct of data: {len(test_inds)/(len(train_inds) + len(test_inds)) * 100}')\n",
    "\n",
    "\n",
    "        np.save('FeatureImportanceResults/test_inds.npy', test_inds)\n",
    "        np.save('FeatureImportanceResults/train_inds.npy', train_inds)\n",
    "        print('New test/train indices generated and read in')\n",
    "\n",
    "    if not NEW_INDICES:\n",
    "        test_inds = np.load('test_inds.npy')\n",
    "        train_inds = np.load('train_inds.npy')\n",
    "        print('Existing test/train indices read in from previous iteration')\n",
    "\n",
    "\n",
    "    #Split data into test/train sets\n",
    "\n",
    "    df_full_test = df_full.iloc[test_inds].reset_index(drop=True)\n",
    "    df_full_train = df_full.iloc[train_inds].reset_index(drop=True)\n",
    "\n",
    "    #test data has only the last year with unseen spatial samples\n",
    "    df_full_test = df_full_test[df_full_test.year == PREDICT_YEAR]\n",
    "\n",
    "    #train data has only the 3 train years \n",
    "    df_full_train = df_full_train[df_full_train.year < PREDICT_YEAR]\n",
    "\n",
    "    Y_test = df_full_test['forest_diff']\n",
    "    Y_train = df_full_train['forest_diff']\n",
    "\n",
    "    X_test = df_full_test[X_cols]\n",
    "    X_train = df_full_train[X_cols]\n",
    "\n",
    "    gdf_test = gpd.GeoDataFrame(X_test, geometry = gpd.points_from_xy(df_full_test.x, df_full_test.y))\n",
    "    gdf_train = gpd.GeoDataFrame(X_train, geometry = gpd.points_from_xy(df_full_train.x, df_full_train.y))\n",
    "\n",
    "    XYs_test = gdf_test['geometry']\n",
    "    XYs_train = gdf_train['geometry']\n",
    "\n",
    "    if PLOT_ENTIRE_AREA and NEW_INDICES:\n",
    "        fig, axs = plt.subplots(1, 1, figsize=(15, 12))\n",
    "        marker_size = 0.1\n",
    "        marker_size = 1\n",
    "        XYs_test.plot(ax=axs, color = 'red', markersize=marker_size, label = 'Test')\n",
    "        XYs_train.plot(ax=axs, color = 'black', markersize=marker_size, label = 'Train')\n",
    "\n",
    "        plt.legend(markerscale=1)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the figure\n",
    "        plt.savefig(FILE_PATH + 'EntirePlot')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    print(np.unique(df_full_test.year))\n",
    "    print(np.unique(df_full_train.year))\n",
    "\n",
    "\n",
    "    NEW_CV_INDICES = True\n",
    "\n",
    "    if NEW_CV_INDICES:\n",
    "        #Select Cross Validation Fold Indices: \n",
    "\n",
    "        n_folds = 5\n",
    "        munis = df_full_train['ID'].values\n",
    "        group_kfold = GroupKFold(n_splits = n_folds)\n",
    "        \n",
    "        \n",
    "        # Generator for the train/test indices\n",
    "        muni_kfold = group_kfold.split(X_train, Y_train, munis) \n",
    "\n",
    "        # Create a nested list of train and test indices for each fold\n",
    "        train_indices, test_indices = [list(traintest) for traintest in zip(*muni_kfold)]\n",
    "        muni_cv = [*zip(train_indices,test_indices)]\n",
    "\n",
    "        #save train and test indices \n",
    "        for i in range(len(train_indices)):\n",
    "            np.savetxt(f'train_indices_{i}.txt', train_indices[i])\n",
    "\n",
    "        for i in range(len(test_indices)):\n",
    "            np.savetxt(f'test_indices_{i}.txt', test_indices[i])\n",
    "\n",
    "        #np.save('FeatureImportanceResults/muni_cv.npy', muni_cv)\n",
    "        print('New test/train indices generated and read in')\n",
    "        \n",
    "\n",
    "\n",
    "    if not NEW_CV_INDICES:\n",
    "        \n",
    "        #read in train and test indices\n",
    "        train_indices = []\n",
    "        for i in range(len(train_indices)):\n",
    "            train_indices.append(np.loadtxt(f'train_indices_{i}.txt'))\n",
    "\n",
    "        test_indices = []\n",
    "        for i in range(len(test_indices)):\n",
    "            test_indices.append(np.loadtxt(f'test_indices_{i}.txt'))\n",
    "\n",
    "        muni_cv = [*zip(train_indices,test_indices)]\n",
    "        #muni_cv = np.load('muni_cv.npy')\n",
    "        \n",
    "        print('Existing test/train cross validation indices read in from previous iteration')\n",
    "\n",
    "\n",
    "    if PLOT_FOLDS and NEW_CV_INDICES: \n",
    "        fig, axs = plt.subplots(1, n_folds, figsize=(25, 16))\n",
    "        marker_size = 0.01\n",
    "\n",
    "        for i in range(n_folds):\n",
    "            ax = axs[i]\n",
    "\n",
    "            this_train_inds = muni_cv[i][0]\n",
    "            this_test_inds = muni_cv[i][1]\n",
    "            XYs_train[this_test_inds].plot(ax=ax, color = 'red', markersize=marker_size, label = 'Test')\n",
    "            XYs_train[this_train_inds].plot(ax=ax, color = 'black', markersize=marker_size, label = 'Train')\n",
    "            ax.set_title(f\"Fold {i+1}\")\n",
    "\n",
    "        #plt.suptitle(f'{n_folds}-Fold Spatial Cross Validation ') \n",
    "        # handles, labels = ax.get_legend_handles_labels()\n",
    "        # fig.legend(handles, labels)   \n",
    "\n",
    "        for ax in axs.flat:\n",
    "            ax.set_axis_off()\n",
    "\n",
    "\n",
    "        plt.legend(markerscale=100)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(FILE_PATH + 'FoldPlot')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    # Count null values in each column\n",
    "    null_counts = {col: X_train[col].isnull().sum() for col in X_train.columns}\n",
    "\n",
    "    # Sort the dictionary in descending order based on the values\n",
    "    sorted_null_counts = dict(sorted(null_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    print(sorted_null_counts)\n",
    "\n",
    "    X_train = X_train.drop('geometry', axis = 1)\n",
    "    X_test = X_test.drop('geometry', axis = 1)\n",
    "\n",
    "    with open(FILE_PATH + 'performance.txt', 'w+') as f:\n",
    "            f.write(f'MODEL PERFORMANCES\\n')\n",
    "\n",
    "    def generate_results_table(coef_input, key_input, name_input, yhat, normalized = True):\n",
    "        if normalized: \n",
    "            coef_input = coef_input / sum(coef_input)\n",
    "\n",
    "        #write MSE to file \n",
    "        mse = mean_squared_error(Y_test, yhat)\n",
    "        print(f'{name_input} MSE: {mse}')\n",
    "\n",
    "        with open(FILE_PATH + 'performance.txt', 'a') as f:\n",
    "            f.write(f'\\n{name_input} MSE: {mse}')\n",
    "\n",
    "\n",
    "        features_df = pd.DataFrame([key_input, coef_input]).T\n",
    "        features_df.columns = ['Feature', 'Coeff']\n",
    "\n",
    "        features_df = features_df.iloc[features_df['Coeff'].abs().argsort()[::-1]]\n",
    "        features_df.to_csv(f'{FILE_PATH}{name_input}.csv')\n",
    "\n",
    "        return features_df\n",
    "\n",
    "\n",
    "    base_learners = []\n",
    "\n",
    "    yhat_list = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #random forest\n",
    "    pipeline = Pipeline([\n",
    "                        ('scaler',StandardScaler()),\n",
    "                        ('model',RandomForestRegressor(n_estimators = 500))\n",
    "    ])\n",
    "\n",
    "    search = GridSearchCV(pipeline,\n",
    "                        {'model__max_depth': np.arange(3,11,8) },\n",
    "                        cv = muni_cv, scoring = \"neg_mean_squared_error\",verbose = 3\n",
    "                        )\n",
    "\n",
    "    search.fit(X_train,Y_train)\n",
    "\n",
    "    base_learners.append(('randomforest', search.best_estimator_))\n",
    "\n",
    "    coefficients = search.best_estimator_._final_estimator.feature_importances_\n",
    "    importance = np.abs(coefficients)\n",
    "\n",
    "    yhat = search.best_estimator_.predict(X_test)\n",
    "    yhat_list.append(yhat)\n",
    "\n",
    "    randomforest_features_df = generate_results_table(coefficients, X_train.columns, 'randomforest', yhat)\n",
    "\n",
    "    X_train.columns[np.argsort(np.array(abs( importance )))[::-1][0:9]]\n",
    "\n",
    "\n",
    "\n",
    "    #lasso \n",
    "\n",
    "    pipeline = Pipeline([\n",
    "                        ('scaler',StandardScaler()),\n",
    "                        ('model',Lasso())\n",
    "    ])\n",
    "\n",
    "    search = GridSearchCV(pipeline,\n",
    "                        {'model__alpha':[1e-15,1e-10,1e-8,1e-3,1e-2,1,5,10,20,30,35,40,45,50,55,100]},\n",
    "                        cv = muni_cv, scoring = \"neg_mean_squared_error\",verbose = 3\n",
    "                        )\n",
    "\n",
    "    search.fit(X_train,Y_train)\n",
    "    base_learners.append(('lasso', search.best_estimator_))\n",
    "\n",
    "    coefficients = search.best_estimator_.named_steps['model'].coef_\n",
    "    importance = np.abs(coefficients)\n",
    "\n",
    "    yhat = search.best_estimator_.predict(X_test)\n",
    "    yhat_list.append(yhat)\n",
    "\n",
    "    lasso_features_df = generate_results_table(coefficients, X_train.columns, 'lasso', yhat = yhat)\n",
    "\n",
    "    X_train.columns[np.argsort(np.array(abs( importance )))[::-1][0:9]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Gradient boosting\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "                        ('scaler',StandardScaler()),\n",
    "                        ('model',GradientBoostingRegressor(learning_rate = 0.1, min_samples_leaf = 2))\n",
    "    ])\n",
    "\n",
    "    search = GridSearchCV(pipeline,\n",
    "                        {'model__n_estimators':np.arange(50, 150, 50), 'model__max_depth':np.arange(3, 5, 1)},\n",
    "                        cv = muni_cv, scoring = \"neg_mean_squared_error\",verbose = 3\n",
    "                        )\n",
    "\n",
    "    search.fit(X_train,Y_train)\n",
    "\n",
    "    search.best_params_\n",
    "\n",
    "    base_learners.append(('gradientboosting', search.best_estimator_.named_steps['model']))\n",
    "\n",
    "    coefficients = search.best_estimator_.named_steps['model'].feature_importances_\n",
    "    importance = np.abs(coefficients)\n",
    "\n",
    "    yhat = search.best_estimator_.predict(X_test)\n",
    "    yhat_list.append(yhat)\n",
    "\n",
    "    gradient_boosting_features_df = generate_results_table(coefficients, X_train.columns, 'gradientboosting', yhat)\n",
    "\n",
    "\n",
    "    X.columns[np.argsort(np.array(abs( importance )))[::-1][0:9]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #neural network\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "                        ('scaler',StandardScaler()),\n",
    "                        ('model', MLPRegressor(activation = 'logistic', random_state=42))\n",
    "    ])\n",
    "\n",
    "    search = GridSearchCV(pipeline,\n",
    "                        {'model__hidden_layer_sizes':[(50,),(100,)], 'model__alpha':np.arange(0.00001, 0.001, 0.001)},\n",
    "                        cv = muni_cv, scoring = \"neg_mean_squared_error\",verbose = 3\n",
    "                        )\n",
    "\n",
    "    search.fit(X_train,Y_train)\n",
    "\n",
    "    base_learners.append(('neuralnetwork', search.best_estimator_))\n",
    "\n",
    "    explainer = shap.KernelExplainer(search.best_estimator_.predict, X_train)\n",
    "\n",
    "    shap_values = explainer.shap_values(X_test, nsamples=100)\n",
    "\n",
    "    shap.summary_plot(shap_values,X_test,feature_names=X_test.columns)\n",
    "\n",
    "    feature_names = X_train.columns\n",
    "\n",
    "    rf_resultX = pd.DataFrame(shap_values, columns = feature_names)\n",
    "\n",
    "    vals = np.abs(rf_resultX.values).mean(0)\n",
    "\n",
    "    shap_importance = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                    columns=['col_name','feature_importance_vals'])\n",
    "    shap_importance.sort_values(by=['feature_importance_vals'],\n",
    "                                ascending=False, inplace=True)\n",
    "\n",
    "    #shap_importance.to_csv('FeatureInportanceResults/neuralnetwork.csv')\n",
    "\n",
    "    yhat = search.best_estimator_.predict(X_test)\n",
    "    yhat_list.append(yhat)\n",
    "\n",
    "    nn_features_df = generate_results_table(np.array(shap_importance.feature_importance_vals), np.array(shap_importance.col_name), 'neuralnetwork', yhat)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #super learner ensemble\n",
    "    def get_models():\n",
    "        base_models = []\n",
    "        #Random forest regressor\n",
    "        base_models.append(base_learners[0][1][1])\n",
    "        #Lasso\n",
    "        base_models.append(base_learners[1][1][1])\n",
    "        #Gradient Boosting\n",
    "        base_models.append(base_learners[2][1])\n",
    "        #NeuralNetwork\n",
    "        base_models.append(base_learners[3][1][1])\n",
    "        return base_models\n",
    "\n",
    "    def get_out_of_fold_predictions(X_train, Y_train, base_models):\n",
    "        meta_X = []\n",
    "        meta_Y = []\n",
    "\n",
    "        # enumerate splits\n",
    "        for train_ix, test_ix in muni_cv:\n",
    "            fold_yhats = []\n",
    "            meta_train_X, meta_test_X = X_train.iloc[train_ix], X_train.iloc[test_ix]\n",
    "            meta_train_Y, meta_test_Y = Y_train.iloc[train_ix], Y_train.iloc[test_ix]\n",
    "            meta_Y.extend(meta_test_Y)\n",
    "\n",
    "            # fit and make predictions with each sub-model\n",
    "            for model in base_models:\n",
    "                model.fit(meta_train_X, meta_train_Y)\n",
    "                yhat = model.predict(meta_test_X)\n",
    "                # store columns\n",
    "                fold_yhats.append(yhat.reshape(len(yhat),1))\n",
    "        \n",
    "            meta_X.append(np.hstack(fold_yhats))\n",
    "                \n",
    "        return np.vstack(meta_X), np.asarray(meta_Y)\n",
    "\n",
    "    def super_learner_predictions(X, models, meta_model):\n",
    "        meta_X = []\n",
    "        for model in models:\n",
    "            yhat = model.predict(X) \n",
    "            meta_X.append(yhat)\n",
    "        # predict\n",
    "        return meta_model.predict(pd.DataFrame(meta_X).T)\n",
    "        \n",
    "    def fit_base_models(X, y, models):\n",
    "        for model in models:\n",
    "            model.fit(X, y)\n",
    "    \n",
    "\n",
    "    def fit_meta_model(X, y):\n",
    "        model = Ridge()\n",
    "        model.fit(X, y)\n",
    "        return model\n",
    "\n",
    "    def evaluate_models(X, y, models):\n",
    "        for model in models:\n",
    "            yhat = model.predict(X)\n",
    "            mse = mean_squared_error(y, yhat)\n",
    "            print('%s: %.3f' % (model.__class__.__name__, mse))\n",
    "\n",
    "    # get models\n",
    "    models = get_models()\n",
    "    # get out of fold predictions\n",
    "    meta_X, meta_y = get_out_of_fold_predictions(X_train, Y_train, models)\n",
    "    print('Meta Data Shape: ', meta_X.shape, meta_y.shape)\n",
    "\n",
    "    fit_base_models(X_train, Y_train, models)\n",
    "    meta_model = fit_meta_model(meta_X, meta_y)\n",
    "\n",
    "    evaluate_models(X_test, Y_test, models)\n",
    "\n",
    "    yhat = super_learner_predictions(X_test, models, meta_model)\n",
    "    yhat_list.append(yhat)\n",
    "\n",
    "    # Evaluate the performance of the model\n",
    "    mse = mean_squared_error(Y_test, yhat)\n",
    "    print(\"MSE:\", mse)\n",
    "\n",
    "\n",
    "    #Super Learner Feature Importance\n",
    "\n",
    "    #Random forest \n",
    "    random_forest_weighted_importance = models[0].feature_importances_ * meta_model.coef_[0]\n",
    "\n",
    "    #Lasso \n",
    "    lasso_weighted_importance = models[1].coef_ * meta_model.coef_[1]\n",
    "\n",
    "    #GradientBoostingRegressor\n",
    "    gradient_boosting_weighted_importance = models[2].feature_importances_ * meta_model.coef_[2]\n",
    "\n",
    "    #NeuralNetwork\n",
    "    explainer = shap.KernelExplainer(models[2].predict, X_train)\n",
    "    shap_values = explainer.shap_values(X_test, nsamples=100)\n",
    "\n",
    "    feature_names = X_train.columns\n",
    "\n",
    "    rf_resultX = pd.DataFrame(shap_values, columns = feature_names)\n",
    "\n",
    "    vals = np.abs(rf_resultX.values).mean(0)\n",
    "\n",
    "    shap_importance = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                    columns=['col_name','feature_importance_vals'])\n",
    "\n",
    "\n",
    "    nn_weighted_importance = shap_importance.feature_importance_vals * meta_model.coef_[3]\n",
    "\n",
    "\n",
    "    super_learner_feature_importance = np.mean([random_forest_weighted_importance, lasso_weighted_importance, gradient_boosting_weighted_importance, nn_weighted_importance], axis = 0)\n",
    "\n",
    "\n",
    "    super_learner_features_df = generate_results_table(super_learner_feature_importance, X_train.columns, 'superlearner', yhat)\n",
    "\n",
    "\n",
    "\n",
    "    #visualize\n",
    "\n",
    "    prediction_df = -pd.DataFrame(yhat_list).T\n",
    "    prediction_df.columns = ['randomforest', 'lasso', 'gradientboosting', 'nn', 'superlearner']\n",
    "    prediction_df['avg'] = prediction_df.mean(axis=1)\n",
    "    prediction_df['x'] = np.array(df_full_test['x'])\n",
    "    prediction_df['y'] = np.array(df_full_test['y'])\n",
    "    prediction_df['actual']  = -np.array(Y_test)\n",
    "    prediction_df.to_csv(FILE_PATH + 'predictions.csv')\n",
    "\n",
    "    for col_name in ['randomforest', 'lasso', 'gradientboosting', 'nn', 'superlearner', 'avg']:\n",
    "        gdf_yhat = gpd.GeoDataFrame(prediction_df, geometry = gpd.points_from_xy(prediction_df.x, prediction_df.y))\n",
    "        fig, axs = plt.subplots(1, 1, figsize=(10, 8))\n",
    "        marker_size = 1\n",
    "        gdf_yhat.plot(column = col_name, cmap = 'Reds', ax=axs, markersize = marker_size)\n",
    "\n",
    "        #plt.legend(markerscale=1)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        \n",
    "\n",
    "        # Show the colorbar\n",
    "        sm = plt.cm.ScalarMappable(cmap = 'Reds')\n",
    "        sm.set_array(prediction_df['avg'])\n",
    "        cbar = plt.colorbar(sm)\n",
    "        \n",
    "\n",
    "        # Save the figure\n",
    "        plt.savefig(FILE_PATH + 'DeforestPlot_' + col_name)\n",
    "\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmuni_cv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmuni_cv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "#Select Test/Train Indices\n",
    "n_folds = 10 \n",
    "munis = df_full['ID'].values\n",
    "group_kfold = GroupKFold(n_splits = n_folds)\n",
    "muni_kfold = group_kfold.split(X, Y, munis) \n",
    "train_indices, test_indices = [list(traintest) for traintest in zip(*muni_kfold)]\n",
    "city_cv = [*zip(train_indices,test_indices)]\n",
    "\n",
    "test_inds = []\n",
    "for i in range(3):\n",
    "    test_inds.extend(city_cv[i][1])\n",
    "\n",
    "train_inds = []\n",
    "for i in range(3, 10):\n",
    "    train_inds.extend(city_cv[i][1])\n",
    "\n",
    "print(f'Test set pct of data: {len(test_inds)/(len(train_inds) + len(test_inds)) * 100}')\n",
    "\n",
    "\n",
    "np.save('FeatureImportanceResults/test_inds.npy', test_inds)\n",
    "np.save('FeatureImportanceResults/train_inds.npy', train_inds)\n",
    "print('New test/train indices generated and read in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f'FeatureImportanceResults/{FOLDER_NAME}'):\n",
    "        os.makedirs(f'{FILE_PATH}TestTrainIndices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Generator for the train/test indices\n",
    "muni_kfold = group_kfold.split(X_train, Y_train, munis) \n",
    "\n",
    "# Create a nested list of train and test indices for each fold\n",
    "train_indices, test_indices = [list(traintest) for traintest in zip(*muni_kfold)]\n",
    "muni_cv = [*zip(train_indices,test_indices)]\n",
    "\n",
    "#save train and test indices \n",
    "for i in range(len(train_indices)):\n",
    "    np.savetxt(f'train_indices_{i}.txt', train_indices[i])\n",
    "\n",
    "for i in range(len(test_indices)):\n",
    "    np.savetxt(f'test_indices_{i}.txt', test_indices[i])\n",
    "\n",
    "#np.save('FeatureImportanceResults/muni_cv.npy', muni_cv)\n",
    "print('New test/train indices generated and read in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in train and test indices\n",
    "train_indices = []\n",
    "for i in range(len(train_indices)):\n",
    "    train_indices.append(np.loadtxt(f'train_indices_{i}.txt'))\n",
    "    \n",
    "test_indices = []\n",
    "for i in range(len(test_indices)):\n",
    "    test_indices.append(np.loadtxt(f'test_indices_{i}.txt'))\n",
    "    \n",
    "muni_cv = [*zip(train_indices,test_indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 2) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmuni_cv\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 2) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# Generator for the train/test indices\n",
    "muni_kfold = group_kfold.split(X_train, Y_train, munis) \n",
    "\n",
    "# Create a nested list of train and test indices for each fold\n",
    "train_indices, test_indices = [list(traintest) for traintest in zip(*muni_kfold)]\n",
    "muni_cv = [*zip(train_indices,test_indices)]\n",
    "\n",
    "np.save('FeatureImportanceResults/muni_cv.npy', muni_cv)\n",
    "print('New test/train indices generated and read in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _BaseKFold.split at 0x2ba3138f9d80>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_kfold.split(X_train, Y_train, munis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_indices\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "np.array(train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_indices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(muni_cv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 2) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmuni_cv\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 2) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "np.array(muni_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Determine the maximum size among the arrays\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m max_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmuni_cv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Pad or truncate arrays to have the same size\u001b[39;00m\n\u001b[1;32m      5\u001b[0m padded_arrays \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mpad(arr, (\u001b[38;5;241m0\u001b[39m, max_size \u001b[38;5;241m-\u001b[39m arr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m array_list]\n",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Determine the maximum size among the arrays\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m max_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m muni_cv)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Pad or truncate arrays to have the same size\u001b[39;00m\n\u001b[1;32m      5\u001b[0m padded_arrays \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mpad(arr, (\u001b[38;5;241m0\u001b[39m, max_size \u001b[38;5;241m-\u001b[39m arr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m array_list]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Determine the maximum size among the arrays\n",
    "max_size = max(arr.shape[0] for arr in muni_cv)\n",
    "\n",
    "# Pad or truncate arrays to have the same size\n",
    "padded_arrays = [np.pad(arr, (0, max_size - arr.shape[0]), mode='constant') for arr in array_list]\n",
    "\n",
    "# Convert list of arrays to NumPy array\n",
    "numpy_array = np.array(padded_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d49eb846d9e9e33562e6444db983d5d3192f0621d82336681e003790fb98d6fc"
  },
  "kernelspec": {
   "display_name": "Python (deforest)",
   "language": "python",
   "name": "deforest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
