{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadr\n",
    "from scipy.spatial import distance\n",
    "from tqdm import tqdm\n",
    "\n",
    "import shapefile as shp  # Requires the pyshp package\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, cross_val_predict\n",
    "import geopandas as gpd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import shap\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2004 2005 2006 2007]\n",
      "(665048, 216)\n",
      "Test set pct of data: 30.0\n",
      "New test/train indices generated and read in\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2007]\n",
      "[2004 2005 2006]\n",
      "New test/train indices generated and read in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'year': 0, 'rain1': 0, 'elevation': 0, 'slope': 0, 'aspect': 0, 'near_mines': 0, 'near_roads': 0, 'near_hidrovia': 0, 'indigenous_homol': 0, 'mun_election_year': 0, 'new_forest_code': 0, 'lula': 0, 'dilma': 0, 'temer': 0, 'bolsonaro': 0, 'fed_election_year': 0, 'populacao': 0, 'pib_pc': 0, 'ironore': 0, 'silver': 0, 'copper': 0, 'gold': 0, 'soy_price': 0, 'beef_price': 0, 'ag_jobs': 0, 'mining_jobs': 0, 'public_jobs': 0, 'construction_jobs': 0, 'PIB': 0, 'n_companies_PUBLIC ADMIN': 0, 'n_companies_AGRICULTURE': 0, 'n_companies_FOOD AND DRINKS': 0, 'n_companies_ACCOMODATION AND FOOD': 0, 'n_companies_EQUIPMENT RENTAL': 0, 'n_companies_WHOLESALE': 0, 'n_companies_ASSOCIATIVE ACTIVITIES': 0, 'n_companies_AUTOMOBILES AND TRANSPORT': 0, 'n_companies_FINANCIAL ASSISTANCE': 0, 'n_companies_TRADE REP VEHICLES': 0, 'n_companies_CONSTRUCTION': 0, 'n_companies_MAIL AND TELECOM': 0, 'n_companies_CULTURE AND SPORT': 0, 'n_companies_EDITING AND PRINTING': 0, 'n_companies_EDUCATION': 0, 'n_companies_ELECTRICITY AND GAS': 0, 'n_companies_FINANCES': 0, 'n_companies_CLEANING AND SEWAGE': 0, 'n_companies_MACHINERY': 0, 'n_companies_BASIC METALLURGY': 0, 'n_companies_MINING': 0, 'n_companies_WOOD PROD': 0, 'n_companies_NON-METALLIC MINERAL PRODUCTS': 0, 'n_companies_HEALTH': 0, 'n_companies_SERVICES FOR COMPANIES': 0, 'n_companies_PERSONAL SERVICES': 0, 'n_companies_TRANSPORTATION': 0, 'n_companies_GROUND TRANSPORT': 0, 'n_companies_WATER TREATMENT AND DISTRIBUTION': 0, 'n_companies_RETAIL': 0, 'n_companies_COMPUTING': 0, 'n_companies_INSURANCE AND SOCIAL SECURITY': 0, 'n_companies_METALLIC PRODUCTS': 0, 'n_companies_DOMESTIC SERVICES': 0, 'n_companies_FORESTRY': 0, 'n_companies_CLOTHING': 0, 'n_companies_PAPER': 0, 'n_companies_INTERNATIONAL BODIES': 0, 'n_companies_OIL AND GAS': 0, 'n_companies_FISHING AND AQUACULTURE': 0, 'n_companies_CHEMICALS': 0, 'n_companies_WATER-BASED TRANSPORTATION': 0, 'n_companies_REAL ESTATE': 0, 'n_companies_RECYCLING': 0, 'n_companies_LEATHERS AND FOOTWEAR': 0, 'n_companies_RUBBER AND PLASTIC': 0, 'n_companies_TEXTILES': 0, 'n_companies_RESEARCH AND DEVELOPMENT': 0, 'n_companies_AERO TRANSPORT': 0, 'n_companies_SMOKE': 0, 'n_companies_PETROLEUM REFINING': 0, 'n_companies_': 0, 'n_jobs_PUBLIC ADMIN': 0, 'n_jobs_AGRICULTURE': 0, 'n_jobs_FOOD AND DRINKS': 0, 'n_jobs_ACCOMODATION AND FOOD': 0, 'n_jobs_EQUIPMENT RENTAL': 0, 'n_jobs_WHOLESALE': 0, 'n_jobs_ASSOCIATIVE ACTIVITIES': 0, 'n_jobs_AUTOMOBILES AND TRANSPORT': 0, 'n_jobs_FINANCIAL ASSISTANCE': 0, 'n_jobs_TRADE REP VEHICLES': 0, 'n_jobs_CONSTRUCTION': 0, 'n_jobs_MAIL AND TELECOM': 0, 'n_jobs_CULTURE AND SPORT': 0, 'n_jobs_EDITING AND PRINTING': 0, 'n_jobs_EDUCATION': 0, 'n_jobs_ELECTRICITY AND GAS': 0, 'n_jobs_FINANCES': 0, 'n_jobs_CLEANING AND SEWAGE': 0, 'n_jobs_MACHINERY': 0, 'n_jobs_BASIC METALLURGY': 0, 'n_jobs_MINING': 0, 'n_jobs_WOOD PROD': 0, 'n_jobs_NON-METALLIC MINERAL PRODUCTS': 0, 'n_jobs_HEALTH': 0, 'n_jobs_SERVICES FOR COMPANIES': 0, 'n_jobs_PERSONAL SERVICES': 0, 'n_jobs_TRANSPORTATION': 0, 'n_jobs_GROUND TRANSPORT': 0, 'n_jobs_WATER TREATMENT AND DISTRIBUTION': 0, 'n_jobs_RETAIL': 0, 'n_jobs_COMPUTING': 0, 'n_jobs_INSURANCE AND SOCIAL SECURITY': 0, 'n_jobs_METALLIC PRODUCTS': 0, 'n_jobs_DOMESTIC SERVICES': 0, 'n_jobs_FORESTRY': 0, 'n_jobs_CLOTHING': 0, 'n_jobs_PAPER': 0, 'n_jobs_INTERNATIONAL BODIES': 0, 'n_jobs_OIL AND GAS': 0, 'n_jobs_FISHING AND AQUACULTURE': 0, 'n_jobs_CHEMICALS': 0, 'n_jobs_WATER-BASED TRANSPORTATION': 0, 'n_jobs_REAL ESTATE': 0, 'n_jobs_RECYCLING': 0, 'n_jobs_LEATHERS AND FOOTWEAR': 0, 'n_jobs_RUBBER AND PLASTIC': 0, 'n_jobs_TEXTILES': 0, 'n_jobs_RESEARCH AND DEVELOPMENT': 0, 'n_jobs_AERO TRANSPORT': 0, 'n_jobs_SMOKE': 0, 'n_jobs_PETROLEUM REFINING': 0, 'n_jobs_': 0, 'n_jobs_TOTAL INDUSTRIAL': 0, 'n_jobs_TOTAL SERVICE': 0, 'n_companies_TOTAL INDUSTRIAL': 0, 'n_companies_TOTAL SERVICE': 0, 'n_companies_TOTAL': 0, 'n_jobs_TOTAL': 0, 'murder_threats': 0, 'assassination': 0, 'assassination_attempt': 0, 'f_emitted_count': 0, 'expen_agri': 0, 'expen_env_man': 0, 'expen_agr_org': 0, 'expen_mining': 0, 'expen_petrol': 0, 'expen_prom_ani_pro': 0, 'expen_prom_veg_pro': 0, 'expen_other_agr': 0, 'expen_agr_defense': 0, 'expen_min_fuel': 0, 'illegal_mining': 0, 'illegal_other': 0, 'illegal_industry': 0, 'audits': 0, 'emiss_pec_full': 0, 'emiss_agr_full': 0, 'emiss_agropec_full': 0, 'incumbant': 0, 'term_limited_seat': 0, 'special': 0, 'overall_winner_complete_college': 0, 'overall_winner_feminino': 0, 'overall_winner_agriculture_job': 0, 'overall_winner_public_service_job': 0, 'overall_winner_health_job': 0, 'overall_winner_corporate_job': 0, 'overall_winner_law_job': 0, 'overall_winner_technical_job': 0, 'overall_winner_professional_job': 0, 'overall_winner_mining_job': 0, 'overall_winner_partido_PT': 0, 'overall_winner_partido_PMDB_MDB': 0, 'overall_winner_partido_PSDB': 0, 'overall_winner_partido_DEM': 0, 'overall_winner_partido_PL': 0, 'overall_winner_partido_other': 0, 'runnerup_partido_PT': 0, 'runnerup_partido_PMDB_MDB': 0, 'runnerup_partido_PSDB': 0, 'runnerup_partido_DEM': 0, 'runnerup_partido_PL': 0, 'runnerup_partido_other': 0, 'winner_votes_proportion': 0, 'vote_participation_proportion': 0, 'forest_formation': 0, 'savanna': 0, 'mangrove': 0, 'silvicultura': 0, 'pasture': 0, 'sugarcane': 0, 'mosaic_ag': 0, 'urban': 0, 'mining': 0, 'water': 0, 'soybean': 0, 'rice': 0, 'other_crop': 0, 'coffee': 0, 'citrus': 0, 'other_perennial': 0, 'forest_lag': 0, 'geometry': 0}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END ...............model__max_depth=3;, score=-0.006 total time=   2.6s\n",
      "[CV 2/5] END ...............model__max_depth=3;, score=-0.009 total time=   2.5s\n",
      "[CV 3/5] END ...............model__max_depth=3;, score=-0.013 total time=   3.0s\n",
      "[CV 4/5] END ...............model__max_depth=3;, score=-0.006 total time=   2.6s\n",
      "[CV 5/5] END ...............model__max_depth=3;, score=-0.004 total time=   2.4s\n",
      "randomforest MSE: 0.0006090945432208227\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END ...............model__alpha=1e-15;, score=-0.003 total time=   0.1s\n",
      "[CV 2/5] END ...............model__alpha=1e-15;, score=-0.002 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.503e-03, tolerance: 2.760e-04\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.293e-03, tolerance: 2.975e-04\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.254e-02, tolerance: 1.852e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...............model__alpha=1e-15;, score=-0.004 total time=   0.1s\n",
      "[CV 4/5] END .............model__alpha=1e-15;, score=-116.272 total time=   0.1s\n",
      "[CV 5/5] END ...............model__alpha=1e-15;, score=-0.000 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.812e-03, tolerance: 2.745e-04\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.698e-03, tolerance: 2.966e-04\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.503e-03, tolerance: 2.760e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...............model__alpha=1e-10;, score=-0.003 total time=   0.1s\n",
      "[CV 2/5] END ...............model__alpha=1e-10;, score=-0.002 total time=   0.1s\n",
      "[CV 3/5] END ...............model__alpha=1e-10;, score=-0.004 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.293e-03, tolerance: 2.975e-04\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.254e-02, tolerance: 1.852e-04\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.812e-03, tolerance: 2.745e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .............model__alpha=1e-10;, score=-116.272 total time=   0.1s\n",
      "[CV 5/5] END ...............model__alpha=1e-10;, score=-0.000 total time=   0.1s\n",
      "[CV 1/5] END ...............model__alpha=1e-08;, score=-0.003 total time=   0.1s\n",
      "[CV 2/5] END ...............model__alpha=1e-08;, score=-0.002 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.698e-03, tolerance: 2.966e-04\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.510e-03, tolerance: 2.760e-04\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.299e-03, tolerance: 2.975e-04\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.254e-02, tolerance: 1.852e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...............model__alpha=1e-08;, score=-0.004 total time=   0.1s\n",
      "[CV 4/5] END .............model__alpha=1e-08;, score=-116.200 total time=   0.1s\n",
      "[CV 5/5] END ...............model__alpha=1e-08;, score=-0.000 total time=   0.1s\n",
      "[CV 1/5] END ...............model__alpha=0.001;, score=-0.005 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.818e-03, tolerance: 2.745e-04\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.704e-03, tolerance: 2.966e-04\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.893e-02, tolerance: 2.760e-04\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.729e-02, tolerance: 2.975e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...............model__alpha=0.001;, score=-0.001 total time=   0.1s\n",
      "[CV 3/5] END ...............model__alpha=0.001;, score=-0.007 total time=   0.0s\n",
      "[CV 4/5] END ..............model__alpha=0.001;, score=-15.662 total time=   0.1s\n",
      "[CV 5/5] END ...............model__alpha=0.001;, score=-0.001 total time=   0.0s\n",
      "[CV 1/5] END ................model__alpha=0.01;, score=-0.006 total time=   0.0s\n",
      "[CV 2/5] END ................model__alpha=0.01;, score=-0.003 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.010e-02, tolerance: 1.852e-04\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.796e-02, tolerance: 2.745e-04\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.468e-02, tolerance: 2.966e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ................model__alpha=0.01;, score=-0.014 total time=   0.0s\n",
      "[CV 4/5] END ................model__alpha=0.01;, score=-0.005 total time=   0.0s\n",
      "[CV 5/5] END ................model__alpha=0.01;, score=-0.003 total time=   0.0s\n",
      "[CV 1/5] END ...................model__alpha=1;, score=-0.005 total time=   0.0s\n",
      "[CV 2/5] END ...................model__alpha=1;, score=-0.003 total time=   0.0s\n",
      "[CV 3/5] END ...................model__alpha=1;, score=-0.014 total time=   0.0s\n",
      "[CV 4/5] END ...................model__alpha=1;, score=-0.006 total time=   0.0s\n",
      "[CV 5/5] END ...................model__alpha=1;, score=-0.003 total time=   0.0s\n",
      "[CV 1/5] END ...................model__alpha=5;, score=-0.005 total time=   0.0s\n",
      "[CV 2/5] END ...................model__alpha=5;, score=-0.003 total time=   0.0s\n",
      "[CV 3/5] END ...................model__alpha=5;, score=-0.014 total time=   0.0s\n",
      "[CV 4/5] END ...................model__alpha=5;, score=-0.006 total time=   0.0s\n",
      "[CV 5/5] END ...................model__alpha=5;, score=-0.003 total time=   0.0s\n",
      "[CV 1/5] END ..................model__alpha=10;, score=-0.005 total time=   0.0s\n",
      "[CV 2/5] END ..................model__alpha=10;, score=-0.003 total time=   0.0s\n",
      "[CV 3/5] END ..................model__alpha=10;, score=-0.014 total time=   0.0s\n",
      "[CV 4/5] END ..................model__alpha=10;, score=-0.006 total time=   0.0s\n",
      "[CV 5/5] END ..................model__alpha=10;, score=-0.003 total time=   0.0s\n",
      "[CV 1/5] END ..................model__alpha=20;, score=-0.005 total time=   0.0s\n",
      "[CV 2/5] END ..................model__alpha=20;, score=-0.003 total time=   0.0s\n",
      "[CV 3/5] END ..................model__alpha=20;, score=-0.014 total time=   0.0s\n",
      "[CV 4/5] END ..................model__alpha=20;, score=-0.006 total time=   0.0s\n",
      "[CV 5/5] END ..................model__alpha=20;, score=-0.003 total time=   0.0s\n",
      "[CV 1/5] END ..................model__alpha=30;, score=-0.005 total time=   0.0s\n",
      "[CV 2/5] END ..................model__alpha=30;, score=-0.003 total time=   0.0s\n",
      "[CV 3/5] END ..................model__alpha=30;, score=-0.014 total time=   0.0s\n",
      "[CV 4/5] END ..................model__alpha=30;, score=-0.006 total time=   0.0s\n",
      "[CV 5/5] END ..................model__alpha=30;, score=-0.003 total time=   0.0s\n",
      "[CV 1/5] END ..................model__alpha=35;, score=-0.005 total time=   0.0s\n",
      "[CV 2/5] END ..................model__alpha=35;, score=-0.003 total time=   0.0s\n",
      "[CV 3/5] END ..................model__alpha=35;, score=-0.014 total time=   0.0s\n",
      "[CV 4/5] END ..................model__alpha=35;, score=-0.006 total time=   0.0s\n",
      "[CV 5/5] END ..................model__alpha=35;, score=-0.003 total time=   0.0s\n",
      "[CV 1/5] END ..................model__alpha=40;, score=-0.005 total time=   0.0s\n",
      "[CV 2/5] END ..................model__alpha=40;, score=-0.003 total time=   0.0s\n",
      "[CV 3/5] END ..................model__alpha=40;, score=-0.014 total time=   0.0s\n",
      "[CV 4/5] END ..................model__alpha=40;, score=-0.006 total time=   0.0s\n",
      "[CV 5/5] END ..................model__alpha=40;, score=-0.003 total time=   0.0s\n",
      "[CV 1/5] END ..................model__alpha=45;, score=-0.005 total time=   0.0s\n",
      "[CV 2/5] END ..................model__alpha=45;, score=-0.003 total time=   0.0s\n",
      "[CV 3/5] END ..................model__alpha=45;, score=-0.014 total time=   0.0s\n",
      "[CV 4/5] END ..................model__alpha=45;, score=-0.006 total time=   0.0s\n",
      "[CV 5/5] END ..................model__alpha=45;, score=-0.003 total time=   0.0s\n",
      "[CV 1/5] END ..................model__alpha=50;, score=-0.005 total time=   0.0s\n",
      "[CV 2/5] END ..................model__alpha=50;, score=-0.003 total time=   0.0s\n",
      "[CV 3/5] END ..................model__alpha=50;, score=-0.014 total time=   0.0s\n",
      "[CV 4/5] END ..................model__alpha=50;, score=-0.006 total time=   0.0s\n",
      "[CV 5/5] END ..................model__alpha=50;, score=-0.003 total time=   0.0s\n",
      "[CV 1/5] END ..................model__alpha=55;, score=-0.005 total time=   0.0s\n",
      "[CV 2/5] END ..................model__alpha=55;, score=-0.003 total time=   0.0s\n",
      "[CV 3/5] END ..................model__alpha=55;, score=-0.014 total time=   0.0s\n",
      "[CV 4/5] END ..................model__alpha=55;, score=-0.006 total time=   0.0s\n",
      "[CV 5/5] END ..................model__alpha=55;, score=-0.003 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=100;, score=-0.005 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=100;, score=-0.003 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=100;, score=-0.014 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=100;, score=-0.006 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=100;, score=-0.003 total time=   0.0s\n",
      "lasso MSE: 0.0005569655880185818\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5] END model__max_depth=3, model__n_estimators=50;, score=-0.006 total time=   0.3s\n",
      "[CV 2/5] END model__max_depth=3, model__n_estimators=50;, score=-0.006 total time=   0.3s\n",
      "[CV 3/5] END model__max_depth=3, model__n_estimators=50;, score=-0.012 total time=   0.3s\n",
      "[CV 4/5] END model__max_depth=3, model__n_estimators=50;, score=-0.006 total time=   0.3s\n",
      "[CV 5/5] END model__max_depth=3, model__n_estimators=50;, score=-0.005 total time=   0.3s\n",
      "[CV 1/5] END model__max_depth=3, model__n_estimators=100;, score=-0.005 total time=   0.6s\n",
      "[CV 2/5] END model__max_depth=3, model__n_estimators=100;, score=-0.005 total time=   0.6s\n",
      "[CV 3/5] END model__max_depth=3, model__n_estimators=100;, score=-0.011 total time=   0.7s\n",
      "[CV 4/5] END model__max_depth=3, model__n_estimators=100;, score=-0.008 total time=   0.7s\n",
      "[CV 5/5] END model__max_depth=3, model__n_estimators=100;, score=-0.006 total time=   0.6s\n",
      "[CV 1/5] END model__max_depth=4, model__n_estimators=50;, score=-0.006 total time=   0.4s\n",
      "[CV 2/5] END model__max_depth=4, model__n_estimators=50;, score=-0.005 total time=   0.4s\n",
      "[CV 3/5] END model__max_depth=4, model__n_estimators=50;, score=-0.011 total time=   0.4s\n",
      "[CV 4/5] END model__max_depth=4, model__n_estimators=50;, score=-0.006 total time=   0.4s\n",
      "[CV 5/5] END model__max_depth=4, model__n_estimators=50;, score=-0.005 total time=   0.4s\n",
      "[CV 1/5] END model__max_depth=4, model__n_estimators=100;, score=-0.006 total time=   0.8s\n",
      "[CV 2/5] END model__max_depth=4, model__n_estimators=100;, score=-0.006 total time=   0.9s\n",
      "[CV 3/5] END model__max_depth=4, model__n_estimators=100;, score=-0.012 total time=   0.8s\n",
      "[CV 4/5] END model__max_depth=4, model__n_estimators=100;, score=-0.006 total time=   0.8s\n",
      "[CV 5/5] END model__max_depth=4, model__n_estimators=100;, score=-0.005 total time=   0.9s\n",
      "gradientboosting MSE: 0.0005906126166507094\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV 1/5] END model__alpha=1e-05, model__hidden_layer_sizes=(50,);, score=-0.023 total time=   0.1s\n",
      "[CV 2/5] END model__alpha=1e-05, model__hidden_layer_sizes=(50,);, score=-0.014 total time=   0.1s\n",
      "[CV 3/5] END model__alpha=1e-05, model__hidden_layer_sizes=(50,);, score=-0.020 total time=   0.1s\n",
      "[CV 4/5] END model__alpha=1e-05, model__hidden_layer_sizes=(50,);, score=-0.020 total time=   0.1s\n",
      "[CV 5/5] END model__alpha=1e-05, model__hidden_layer_sizes=(50,);, score=-0.008 total time=   0.1s\n",
      "[CV 1/5] END model__alpha=1e-05, model__hidden_layer_sizes=(100,);, score=-0.017 total time=   0.1s\n",
      "[CV 2/5] END model__alpha=1e-05, model__hidden_layer_sizes=(100,);, score=-0.035 total time=   0.2s\n",
      "[CV 3/5] END model__alpha=1e-05, model__hidden_layer_sizes=(100,);, score=-0.023 total time=   0.2s\n",
      "[CV 4/5] END model__alpha=1e-05, model__hidden_layer_sizes=(100,);, score=-0.017 total time=   0.2s\n",
      "[CV 5/5] END model__alpha=1e-05, model__hidden_layer_sizes=(100,);, score=-0.011 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "Using 517 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n",
      "  0%|          | 0/71 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "first_time = True\n",
    "\n",
    "for this_start_year in tqdm([2004, 2005]):\n",
    "    SUBSET = True\n",
    "    SUBSET_SIZE = 1000\n",
    "\n",
    "    if first_time: \n",
    "        NEW_INDICES = True\n",
    "        NEW_CV_INDICES = True\n",
    "        first_time = False\n",
    "    else: \n",
    "        NEW_INDICES = False\n",
    "        NEW_CV_INDICES = False\n",
    "\n",
    "    PLOT_ENTIRE_AREA = True\n",
    "    PLOT_FOLDS = False\n",
    "\n",
    "    START_YEAR_TRAIN = this_start_year\n",
    "    NUMBER_YEARS_TRAIN = 3\n",
    "    YEARS_TO_TRAIN = [START_YEAR_TRAIN + i  for i in range(NUMBER_YEARS_TRAIN + 1)]\n",
    "\n",
    "    PREDICT_YEAR = START_YEAR_TRAIN + NUMBER_YEARS_TRAIN\n",
    "\n",
    "    FOLDER_NAME = ''.join([f'{START_YEAR_TRAIN + i}_' for i in list(range(NUMBER_YEARS_TRAIN))]) + f'PREDICT_{PREDICT_YEAR}'\n",
    "\n",
    "\n",
    "    FILE_PATH = f'FeatureImportanceResults/{FOLDER_NAME}/'\n",
    "\n",
    "    if not os.path.exists(f'FeatureImportanceResults/{FOLDER_NAME}'):\n",
    "        os.makedirs(f'FeatureImportanceResults/{FOLDER_NAME}')\n",
    "        \n",
    "        \n",
    "    df_full = pd.read_csv(f'FinalData/FinalData{START_YEAR_TRAIN}_1.csv')\n",
    "    df_full = pd.concat([df_full, pd.read_csv(f'FinalData/FinalData{START_YEAR_TRAIN}_2.csv')])\n",
    "    df_full = pd.concat([df_full, pd.read_csv(f'FinalData/FinalData{START_YEAR_TRAIN}_3.csv')])\n",
    "    df_full = pd.concat([df_full, pd.read_csv(f'FinalData/FinalData{START_YEAR_TRAIN}_4.csv')])\n",
    "\n",
    "\n",
    "    for year in YEARS_TO_TRAIN[1:]:\n",
    "        filename = f'FinalData/FinalData{str(year)}_1.csv'\n",
    "        df_full = pd.concat([df_full, pd.read_csv(filename)])\n",
    "        filename = f'FinalData/FinalData{str(year)}_2.csv'\n",
    "        df_full = pd.concat([df_full, pd.read_csv(filename)])\n",
    "        filename = f'FinalData/FinalData{str(year)}_3.csv'\n",
    "        df_full = pd.concat([df_full, pd.read_csv(filename)])\n",
    "        filename = f'FinalData/FinalData{str(year)}_4.csv'\n",
    "        df_full = pd.concat([df_full, pd.read_csv(filename)])\n",
    "\n",
    "    print(np.unique(df_full.year))\n",
    "    print(df_full.shape)\n",
    "\n",
    "\n",
    "    X_cols  = ['year', 'rain1', 'elevation', 'slope', 'aspect', 'near_mines',\n",
    "        'near_roads', 'near_hidrovia', 'indigenous_homol',\n",
    "        'mun_election_year', 'new_forest_code', 'lula', 'dilma', 'temer',\n",
    "        'bolsonaro', 'fed_election_year', 'populacao', 'pib_pc', 'ironore',\n",
    "        'silver', 'copper', 'gold', 'soy_price', 'beef_price', 'ag_jobs',\n",
    "        'mining_jobs', 'public_jobs', 'construction_jobs', 'PIB',\n",
    "        'n_companies_PUBLIC ADMIN', 'n_companies_AGRICULTURE',\n",
    "        'n_companies_FOOD AND DRINKS', 'n_companies_ACCOMODATION AND FOOD',\n",
    "        'n_companies_EQUIPMENT RENTAL', 'n_companies_WHOLESALE',\n",
    "        'n_companies_ASSOCIATIVE ACTIVITIES',\n",
    "        'n_companies_AUTOMOBILES AND TRANSPORT',\n",
    "        'n_companies_FINANCIAL ASSISTANCE',\n",
    "        'n_companies_TRADE REP VEHICLES', 'n_companies_CONSTRUCTION',\n",
    "        'n_companies_MAIL AND TELECOM', 'n_companies_CULTURE AND SPORT',\n",
    "        'n_companies_EDITING AND PRINTING', 'n_companies_EDUCATION',\n",
    "        'n_companies_ELECTRICITY AND GAS', 'n_companies_FINANCES',\n",
    "        'n_companies_CLEANING AND SEWAGE', 'n_companies_MACHINERY',\n",
    "        'n_companies_BASIC METALLURGY', 'n_companies_MINING',\n",
    "        'n_companies_WOOD PROD',\n",
    "        'n_companies_NON-METALLIC MINERAL PRODUCTS', 'n_companies_HEALTH',\n",
    "        'n_companies_SERVICES FOR COMPANIES',\n",
    "        'n_companies_PERSONAL SERVICES', 'n_companies_TRANSPORTATION',\n",
    "        'n_companies_GROUND TRANSPORT',\n",
    "        'n_companies_WATER TREATMENT AND DISTRIBUTION',\n",
    "        'n_companies_RETAIL', 'n_companies_COMPUTING',\n",
    "        'n_companies_INSURANCE AND SOCIAL SECURITY',\n",
    "        'n_companies_METALLIC PRODUCTS', 'n_companies_DOMESTIC SERVICES',\n",
    "        'n_companies_FORESTRY', 'n_companies_CLOTHING',\n",
    "        'n_companies_PAPER', 'n_companies_INTERNATIONAL BODIES',\n",
    "        'n_companies_OIL AND GAS', 'n_companies_FISHING AND AQUACULTURE',\n",
    "        'n_companies_CHEMICALS', 'n_companies_WATER-BASED TRANSPORTATION',\n",
    "        'n_companies_REAL ESTATE', 'n_companies_RECYCLING',\n",
    "        'n_companies_LEATHERS AND FOOTWEAR',\n",
    "        'n_companies_RUBBER AND PLASTIC', 'n_companies_TEXTILES',\n",
    "        'n_companies_RESEARCH AND DEVELOPMENT',\n",
    "        'n_companies_AERO TRANSPORT', 'n_companies_SMOKE',\n",
    "        'n_companies_PETROLEUM REFINING', 'n_companies_',\n",
    "        'n_jobs_PUBLIC ADMIN', 'n_jobs_AGRICULTURE',\n",
    "        'n_jobs_FOOD AND DRINKS', 'n_jobs_ACCOMODATION AND FOOD',\n",
    "        'n_jobs_EQUIPMENT RENTAL', 'n_jobs_WHOLESALE',\n",
    "        'n_jobs_ASSOCIATIVE ACTIVITIES',\n",
    "        'n_jobs_AUTOMOBILES AND TRANSPORT', 'n_jobs_FINANCIAL ASSISTANCE',\n",
    "        'n_jobs_TRADE REP VEHICLES', 'n_jobs_CONSTRUCTION',\n",
    "        'n_jobs_MAIL AND TELECOM', 'n_jobs_CULTURE AND SPORT',\n",
    "        'n_jobs_EDITING AND PRINTING', 'n_jobs_EDUCATION',\n",
    "        'n_jobs_ELECTRICITY AND GAS', 'n_jobs_FINANCES',\n",
    "        'n_jobs_CLEANING AND SEWAGE', 'n_jobs_MACHINERY',\n",
    "        'n_jobs_BASIC METALLURGY', 'n_jobs_MINING', 'n_jobs_WOOD PROD',\n",
    "        'n_jobs_NON-METALLIC MINERAL PRODUCTS', 'n_jobs_HEALTH',\n",
    "        'n_jobs_SERVICES FOR COMPANIES', 'n_jobs_PERSONAL SERVICES',\n",
    "        'n_jobs_TRANSPORTATION', 'n_jobs_GROUND TRANSPORT',\n",
    "        'n_jobs_WATER TREATMENT AND DISTRIBUTION', 'n_jobs_RETAIL',\n",
    "        'n_jobs_COMPUTING', 'n_jobs_INSURANCE AND SOCIAL SECURITY',\n",
    "        'n_jobs_METALLIC PRODUCTS', 'n_jobs_DOMESTIC SERVICES',\n",
    "        'n_jobs_FORESTRY', 'n_jobs_CLOTHING', 'n_jobs_PAPER',\n",
    "        'n_jobs_INTERNATIONAL BODIES', 'n_jobs_OIL AND GAS',\n",
    "        'n_jobs_FISHING AND AQUACULTURE', 'n_jobs_CHEMICALS',\n",
    "        'n_jobs_WATER-BASED TRANSPORTATION', 'n_jobs_REAL ESTATE',\n",
    "        'n_jobs_RECYCLING', 'n_jobs_LEATHERS AND FOOTWEAR',\n",
    "        'n_jobs_RUBBER AND PLASTIC', 'n_jobs_TEXTILES',\n",
    "        'n_jobs_RESEARCH AND DEVELOPMENT', 'n_jobs_AERO TRANSPORT',\n",
    "        'n_jobs_SMOKE', 'n_jobs_PETROLEUM REFINING', 'n_jobs_',\n",
    "        'n_jobs_TOTAL INDUSTRIAL', 'n_jobs_TOTAL SERVICE',\n",
    "        'n_companies_TOTAL INDUSTRIAL', 'n_companies_TOTAL SERVICE',\n",
    "        'n_companies_TOTAL', 'n_jobs_TOTAL', 'murder_threats',\n",
    "        'assassination', 'assassination_attempt', 'f_emitted_count',\n",
    "        'expen_agri', 'expen_env_man', 'expen_agr_org', 'expen_mining',\n",
    "        'expen_petrol', 'expen_prom_ani_pro', 'expen_prom_veg_pro',\n",
    "        'expen_other_agr', 'expen_agr_defense', 'expen_min_fuel',\n",
    "        'illegal_mining', 'illegal_other', 'illegal_industry', 'audits',\n",
    "        'emiss_pec_full', 'emiss_agr_full', 'emiss_agropec_full',\n",
    "        'incumbant', 'term_limited_seat', 'special',\n",
    "        'overall_winner_complete_college', \n",
    "        'overall_winner_feminino', 'overall_winner_agriculture_job',\n",
    "        'overall_winner_public_service_job', 'overall_winner_health_job',\n",
    "        'overall_winner_corporate_job', 'overall_winner_law_job',\n",
    "        'overall_winner_technical_job', 'overall_winner_professional_job',\n",
    "        'overall_winner_mining_job', 'overall_winner_partido_PT',\n",
    "        'overall_winner_partido_PMDB_MDB', 'overall_winner_partido_PSDB',\n",
    "        'overall_winner_partido_DEM', 'overall_winner_partido_PL',\n",
    "        'overall_winner_partido_other', 'runnerup_partido_PT',\n",
    "        'runnerup_partido_PMDB_MDB', 'runnerup_partido_PSDB',\n",
    "        'runnerup_partido_DEM', 'runnerup_partido_PL',\n",
    "        'runnerup_partido_other', 'winner_votes_proportion',\n",
    "        'vote_participation_proportion',\n",
    "        'forest_formation', 'savanna', 'mangrove', 'silvicultura',\n",
    "        'pasture', 'sugarcane', 'mosaic_ag', 'urban', 'mining', 'water',\n",
    "        'soybean', 'rice', 'other_crop', 'coffee', 'citrus',\n",
    "        'other_perennial', 'forest_lag']\n",
    "\n",
    "\n",
    "    #'runnerup_votes_proportion', \n",
    "    #'overall_winner_idade',\n",
    "\n",
    "\n",
    "    ## Test train split\n",
    "    #split into two groups where no muni in train set is tested\n",
    "    #then do a second split by year so that the train years are year n, n+1, n+2 and the test set uses n+3.\n",
    "    if SUBSET:\n",
    "        df_full = df_full.sample(SUBSET_SIZE).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    Y = df_full['forest_diff']\n",
    "    X = df_full[X_cols]\n",
    "    # gdf = gpd.GeoDataFrame(X, geometry = gpd.points_from_xy(df_full.x, df_full.y))\n",
    "    # XYs = gdf['geometry']\n",
    "\n",
    "\n",
    "    if NEW_INDICES:\n",
    "\n",
    "        #Select Test/Train Indices\n",
    "        n_folds = 10 \n",
    "        munis = df_full['ID'].values\n",
    "        group_kfold = GroupKFold(n_splits = n_folds)\n",
    "        muni_kfold = group_kfold.split(X, Y, munis) \n",
    "        train_indices, test_indices = [list(traintest) for traintest in zip(*muni_kfold)]\n",
    "        city_cv = [*zip(train_indices,test_indices)]\n",
    "\n",
    "        test_inds = []\n",
    "        for i in range(3):\n",
    "            test_inds.extend(city_cv[i][1])\n",
    "\n",
    "        train_inds = []\n",
    "        for i in range(3, 10):\n",
    "            train_inds.extend(city_cv[i][1])\n",
    "\n",
    "        print(f'Test set pct of data: {len(test_inds)/(len(train_inds) + len(test_inds)) * 100}')\n",
    "\n",
    "\n",
    "        np.save('FeatureImportanceResults/test_inds.npy', test_inds)\n",
    "        np.save('FeatureImportanceResults/train_inds.npy', train_inds)\n",
    "        print('New test/train indices generated and read in')\n",
    "\n",
    "    if not NEW_INDICES:\n",
    "        test_inds = np.load('test_inds.npy')\n",
    "        train_inds = np.load('train_inds.npy')\n",
    "        print('Existing test/train indices read in from previous iteration')\n",
    "\n",
    "\n",
    "    #Split data into test/train sets\n",
    "\n",
    "    df_full_test = df_full.iloc[test_inds].reset_index(drop=True)\n",
    "    df_full_train = df_full.iloc[train_inds].reset_index(drop=True)\n",
    "\n",
    "    #test data has only the last year with unseen spatial samples\n",
    "    df_full_test = df_full_test[df_full_test.year == PREDICT_YEAR]\n",
    "\n",
    "    #train data has only the 3 train years \n",
    "    df_full_train = df_full_train[df_full_train.year < PREDICT_YEAR]\n",
    "\n",
    "    Y_test = df_full_test['forest_diff']\n",
    "    Y_train = df_full_train['forest_diff']\n",
    "\n",
    "    X_test = df_full_test[X_cols]\n",
    "    X_train = df_full_train[X_cols]\n",
    "\n",
    "    gdf_test = gpd.GeoDataFrame(X_test, geometry = gpd.points_from_xy(df_full_test.x, df_full_test.y))\n",
    "    gdf_train = gpd.GeoDataFrame(X_train, geometry = gpd.points_from_xy(df_full_train.x, df_full_train.y))\n",
    "\n",
    "    XYs_test = gdf_test['geometry']\n",
    "    XYs_train = gdf_train['geometry']\n",
    "\n",
    "    if PLOT_ENTIRE_AREA and NEW_INDICES:\n",
    "        fig, axs = plt.subplots(1, 1, figsize=(15, 12))\n",
    "        marker_size = 0.1\n",
    "        marker_size = 1\n",
    "        XYs_test.plot(ax=axs, color = 'red', markersize=marker_size, label = 'Test')\n",
    "        XYs_train.plot(ax=axs, color = 'black', markersize=marker_size, label = 'Train')\n",
    "\n",
    "        plt.legend(markerscale=1)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the figure\n",
    "        plt.savefig(FILE_PATH + 'EntirePlot')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    print(np.unique(df_full_test.year))\n",
    "    print(np.unique(df_full_train.year))\n",
    "\n",
    "\n",
    "    NEW_CV_INDICES = True\n",
    "\n",
    "    if NEW_CV_INDICES:\n",
    "        #Select Cross Validation Fold Indices: \n",
    "\n",
    "        n_folds = 5\n",
    "        munis = df_full_train['ID'].values\n",
    "        group_kfold = GroupKFold(n_splits = n_folds)\n",
    "\n",
    "        # Generator for the train/test indices\n",
    "        muni_kfold = group_kfold.split(X_train, Y_train, munis) \n",
    "\n",
    "        # Create a nested list of train and test indices for each fold\n",
    "        train_indices, test_indices = [list(traintest) for traintest in zip(*muni_kfold)]\n",
    "        muni_cv = [*zip(train_indices,test_indices)]\n",
    "\n",
    "        np.save('FeatureImportanceResults/muni_cv.npy', muni_cv)\n",
    "        print('New test/train indices generated and read in')\n",
    "\n",
    "    if not NEW_CV_INDICES:\n",
    "        muni_cv = np.load('muni_cv.npy')\n",
    "        print('Existing test/train cross validation indices read in from previous iteration')\n",
    "\n",
    "\n",
    "    if PLOT_FOLDS and NEW_CV_INDICES: \n",
    "        fig, axs = plt.subplots(1, n_folds, figsize=(25, 16))\n",
    "        marker_size = 0.01\n",
    "\n",
    "        for i in range(n_folds):\n",
    "            ax = axs[i]\n",
    "\n",
    "            this_train_inds = muni_cv[i][0]\n",
    "            this_test_inds = muni_cv[i][1]\n",
    "            XYs_train[this_test_inds].plot(ax=ax, color = 'red', markersize=marker_size, label = 'Test')\n",
    "            XYs_train[this_train_inds].plot(ax=ax, color = 'black', markersize=marker_size, label = 'Train')\n",
    "            ax.set_title(f\"Fold {i+1}\")\n",
    "\n",
    "        #plt.suptitle(f'{n_folds}-Fold Spatial Cross Validation ') \n",
    "        # handles, labels = ax.get_legend_handles_labels()\n",
    "        # fig.legend(handles, labels)   \n",
    "\n",
    "        for ax in axs.flat:\n",
    "            ax.set_axis_off()\n",
    "\n",
    "\n",
    "        plt.legend(markerscale=100)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(FILE_PATH + 'FoldPlot')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    # Count null values in each column\n",
    "    null_counts = {col: X_train[col].isnull().sum() for col in X_train.columns}\n",
    "\n",
    "    # Sort the dictionary in descending order based on the values\n",
    "    sorted_null_counts = dict(sorted(null_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    print(sorted_null_counts)\n",
    "\n",
    "    X_train = X_train.drop('geometry', axis = 1)\n",
    "    X_test = X_test.drop('geometry', axis = 1)\n",
    "\n",
    "    with open(FILE_PATH + 'performance.txt', 'w+') as f:\n",
    "            f.write(f'MODEL PERFORMANCES\\n')\n",
    "\n",
    "    def generate_results_table(coef_input, key_input, name_input, yhat, normalized = True):\n",
    "        if normalized: \n",
    "            coef_input = coef_input / sum(coef_input)\n",
    "\n",
    "        #write MSE to file \n",
    "        mse = mean_squared_error(Y_test, yhat)\n",
    "        print(f'{name_input} MSE: {mse}')\n",
    "\n",
    "        with open(FILE_PATH + 'performance.txt', 'a') as f:\n",
    "            f.write(f'\\n{name_input} MSE: {mse}')\n",
    "\n",
    "\n",
    "        features_df = pd.DataFrame([key_input, coef_input]).T\n",
    "        features_df.columns = ['Feature', 'Coeff']\n",
    "\n",
    "        features_df = features_df.iloc[features_df['Coeff'].abs().argsort()[::-1]]\n",
    "        features_df.to_csv(f'{FILE_PATH}{name_input}.csv')\n",
    "\n",
    "        return features_df\n",
    "\n",
    "\n",
    "    base_learners = []\n",
    "\n",
    "    yhat_list = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #random forest\n",
    "    pipeline = Pipeline([\n",
    "                        ('scaler',StandardScaler()),\n",
    "                        ('model',RandomForestRegressor(n_estimators = 500))\n",
    "    ])\n",
    "\n",
    "    search = GridSearchCV(pipeline,\n",
    "                        {'model__max_depth': np.arange(3,11,8) },\n",
    "                        cv = muni_cv, scoring = \"neg_mean_squared_error\",verbose = 3\n",
    "                        )\n",
    "\n",
    "    search.fit(X_train,Y_train)\n",
    "\n",
    "    base_learners.append(('randomforest', search.best_estimator_))\n",
    "\n",
    "    coefficients = search.best_estimator_._final_estimator.feature_importances_\n",
    "    importance = np.abs(coefficients)\n",
    "\n",
    "    yhat = search.best_estimator_.predict(X_test)\n",
    "    yhat_list.append(yhat)\n",
    "\n",
    "    randomforest_features_df = generate_results_table(coefficients, X_train.columns, 'randomforest', yhat)\n",
    "\n",
    "    X_train.columns[np.argsort(np.array(abs( importance )))[::-1][0:9]]\n",
    "\n",
    "\n",
    "\n",
    "    #lasso \n",
    "\n",
    "    pipeline = Pipeline([\n",
    "                        ('scaler',StandardScaler()),\n",
    "                        ('model',Lasso())\n",
    "    ])\n",
    "\n",
    "    search = GridSearchCV(pipeline,\n",
    "                        {'model__alpha':[1e-15,1e-10,1e-8,1e-3,1e-2,1,5,10,20,30,35,40,45,50,55,100]},\n",
    "                        cv = muni_cv, scoring = \"neg_mean_squared_error\",verbose = 3\n",
    "                        )\n",
    "\n",
    "    search.fit(X_train,Y_train)\n",
    "    base_learners.append(('lasso', search.best_estimator_))\n",
    "\n",
    "    coefficients = search.best_estimator_.named_steps['model'].coef_\n",
    "    importance = np.abs(coefficients)\n",
    "\n",
    "    yhat = search.best_estimator_.predict(X_test)\n",
    "    yhat_list.append(yhat)\n",
    "\n",
    "    lasso_features_df = generate_results_table(coefficients, X_train.columns, 'lasso', yhat = yhat)\n",
    "\n",
    "    X_train.columns[np.argsort(np.array(abs( importance )))[::-1][0:9]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Gradient boosting\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "                        ('scaler',StandardScaler()),\n",
    "                        ('model',GradientBoostingRegressor(learning_rate = 0.1, min_samples_leaf = 2))\n",
    "    ])\n",
    "\n",
    "    search = GridSearchCV(pipeline,\n",
    "                        {'model__n_estimators':np.arange(50, 150, 50), 'model__max_depth':np.arange(3, 5, 1)},\n",
    "                        cv = muni_cv, scoring = \"neg_mean_squared_error\",verbose = 3\n",
    "                        )\n",
    "\n",
    "    search.fit(X_train,Y_train)\n",
    "\n",
    "    search.best_params_\n",
    "\n",
    "    base_learners.append(('gradientboosting', search.best_estimator_.named_steps['model']))\n",
    "\n",
    "    coefficients = search.best_estimator_.named_steps['model'].feature_importances_\n",
    "    importance = np.abs(coefficients)\n",
    "\n",
    "    yhat = search.best_estimator_.predict(X_test)\n",
    "    yhat_list.append(yhat)\n",
    "\n",
    "    gradient_boosting_features_df = generate_results_table(coefficients, X_train.columns, 'gradientboosting', yhat)\n",
    "\n",
    "\n",
    "    X.columns[np.argsort(np.array(abs( importance )))[::-1][0:9]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #neural network\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "                        ('scaler',StandardScaler()),\n",
    "                        ('model', MLPRegressor(activation = 'logistic', random_state=42))\n",
    "    ])\n",
    "\n",
    "    search = GridSearchCV(pipeline,\n",
    "                        {'model__hidden_layer_sizes':[(50,),(100,)], 'model__alpha':np.arange(0.00001, 0.001, 0.001)},\n",
    "                        cv = muni_cv, scoring = \"neg_mean_squared_error\",verbose = 3\n",
    "                        )\n",
    "\n",
    "    search.fit(X_train,Y_train)\n",
    "\n",
    "    base_learners.append(('neuralnetwork', search.best_estimator_))\n",
    "\n",
    "    explainer = shap.KernelExplainer(search.best_estimator_.predict, X_train)\n",
    "\n",
    "    shap_values = explainer.shap_values(X_test, nsamples=100)\n",
    "\n",
    "    shap.summary_plot(shap_values,X_test,feature_names=X_test.columns)\n",
    "\n",
    "    feature_names = X_train.columns\n",
    "\n",
    "    rf_resultX = pd.DataFrame(shap_values, columns = feature_names)\n",
    "\n",
    "    vals = np.abs(rf_resultX.values).mean(0)\n",
    "\n",
    "    shap_importance = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                    columns=['col_name','feature_importance_vals'])\n",
    "    shap_importance.sort_values(by=['feature_importance_vals'],\n",
    "                                ascending=False, inplace=True)\n",
    "\n",
    "    #shap_importance.to_csv('FeatureInportanceResults/neuralnetwork.csv')\n",
    "\n",
    "    yhat = search.best_estimator_.predict(X_test)\n",
    "    yhat_list.append(yhat)\n",
    "\n",
    "    nn_features_df = generate_results_table(np.array(shap_importance.feature_importance_vals), np.array(shap_importance.col_name), 'neuralnetwork', yhat)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #super learner ensemble\n",
    "    def get_models():\n",
    "        base_models = []\n",
    "        #Random forest regressor\n",
    "        base_models.append(base_learners[0][1][1])\n",
    "        #Lasso\n",
    "        base_models.append(base_learners[1][1][1])\n",
    "        #Gradient Boosting\n",
    "        base_models.append(base_learners[2][1])\n",
    "        #NeuralNetwork\n",
    "        base_models.append(base_learners[3][1][1])\n",
    "        return base_models\n",
    "\n",
    "    def get_out_of_fold_predictions(X_train, Y_train, base_models):\n",
    "        meta_X = []\n",
    "        meta_Y = []\n",
    "\n",
    "        # enumerate splits\n",
    "        for train_ix, test_ix in muni_cv:\n",
    "            fold_yhats = []\n",
    "            meta_train_X, meta_test_X = X_train.iloc[train_ix], X_train.iloc[test_ix]\n",
    "            meta_train_Y, meta_test_Y = Y_train.iloc[train_ix], Y_train.iloc[test_ix]\n",
    "            meta_Y.extend(meta_test_Y)\n",
    "\n",
    "            # fit and make predictions with each sub-model\n",
    "            for model in base_models:\n",
    "                model.fit(meta_train_X, meta_train_Y)\n",
    "                yhat = model.predict(meta_test_X)\n",
    "                # store columns\n",
    "                fold_yhats.append(yhat.reshape(len(yhat),1))\n",
    "        \n",
    "            meta_X.append(np.hstack(fold_yhats))\n",
    "                \n",
    "        return np.vstack(meta_X), np.asarray(meta_Y)\n",
    "\n",
    "    def super_learner_predictions(X, models, meta_model):\n",
    "        meta_X = []\n",
    "        for model in models:\n",
    "            yhat = model.predict(X) \n",
    "            meta_X.append(yhat)\n",
    "        # predict\n",
    "        return meta_model.predict(pd.DataFrame(meta_X).T)\n",
    "        \n",
    "    def fit_base_models(X, y, models):\n",
    "        for model in models:\n",
    "            model.fit(X, y)\n",
    "    \n",
    "\n",
    "    def fit_meta_model(X, y):\n",
    "        model = Ridge()\n",
    "        model.fit(X, y)\n",
    "        return model\n",
    "\n",
    "    def evaluate_models(X, y, models):\n",
    "        for model in models:\n",
    "            yhat = model.predict(X)\n",
    "            mse = mean_squared_error(y, yhat)\n",
    "            print('%s: %.3f' % (model.__class__.__name__, mse))\n",
    "\n",
    "    # get models\n",
    "    models = get_models()\n",
    "    # get out of fold predictions\n",
    "    meta_X, meta_y = get_out_of_fold_predictions(X_train, Y_train, models)\n",
    "    print('Meta Data Shape: ', meta_X.shape, meta_y.shape)\n",
    "\n",
    "    fit_base_models(X_train, Y_train, models)\n",
    "    meta_model = fit_meta_model(meta_X, meta_y)\n",
    "\n",
    "    evaluate_models(X_test, Y_test, models)\n",
    "\n",
    "    yhat = super_learner_predictions(X_test, models, meta_model)\n",
    "    yhat_list.append(yhat)\n",
    "\n",
    "    # Evaluate the performance of the model\n",
    "    mse = mean_squared_error(Y_test, yhat)\n",
    "    print(\"MSE:\", mse)\n",
    "\n",
    "\n",
    "    #Super Learner Feature Importance\n",
    "\n",
    "    #Random forest \n",
    "    random_forest_weighted_importance = models[0].feature_importances_ * meta_model.coef_[0]\n",
    "\n",
    "    #Lasso \n",
    "    lasso_weighted_importance = models[1].coef_ * meta_model.coef_[1]\n",
    "\n",
    "    #GradientBoostingRegressor\n",
    "    gradient_boosting_weighted_importance = models[2].feature_importances_ * meta_model.coef_[2]\n",
    "\n",
    "    #NeuralNetwork\n",
    "    explainer = shap.KernelExplainer(models[2].predict, X_train)\n",
    "    shap_values = explainer.shap_values(X_test, nsamples=100)\n",
    "\n",
    "    feature_names = X_train.columns\n",
    "\n",
    "    rf_resultX = pd.DataFrame(shap_values, columns = feature_names)\n",
    "\n",
    "    vals = np.abs(rf_resultX.values).mean(0)\n",
    "\n",
    "    shap_importance = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                    columns=['col_name','feature_importance_vals'])\n",
    "\n",
    "\n",
    "    nn_weighted_importance = shap_importance.feature_importance_vals * meta_model.coef_[3]\n",
    "\n",
    "\n",
    "    super_learner_feature_importance = np.mean([random_forest_weighted_importance, lasso_weighted_importance, gradient_boosting_weighted_importance, nn_weighted_importance], axis = 0)\n",
    "\n",
    "\n",
    "    super_learner_features_df = generate_results_table(super_learner_feature_importance, X_train.columns, 'superlearner', yhat)\n",
    "\n",
    "\n",
    "\n",
    "    #visualize\n",
    "\n",
    "    prediction_df = -pd.DataFrame(yhat_list).T\n",
    "    prediction_df.columns = ['randomforest', 'lasso', 'gradientboosting', 'nn', 'superlearner']\n",
    "    prediction_df['avg'] = prediction_df.mean(axis=1)\n",
    "    prediction_df['x'] = np.array(df_full_test['x'])\n",
    "    prediction_df['y'] = np.array(df_full_test['y'])\n",
    "    prediction_df['actual']  = -np.array(Y_test)\n",
    "    prediction_df.to_csv(FILE_PATH + 'predictions.csv')\n",
    "\n",
    "    for col_name in ['randomforest', 'lasso', 'gradientboosting', 'nn', 'superlearner', 'avg']:\n",
    "        gdf_yhat = gpd.GeoDataFrame(prediction_df, geometry = gpd.points_from_xy(prediction_df.x, prediction_df.y))\n",
    "        fig, axs = plt.subplots(1, 1, figsize=(10, 8))\n",
    "        marker_size = 1\n",
    "        gdf_yhat.plot(column = col_name, cmap = 'Reds', ax=axs, markersize = marker_size)\n",
    "\n",
    "        #plt.legend(markerscale=1)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        \n",
    "\n",
    "        # Show the colorbar\n",
    "        sm = plt.cm.ScalarMappable(cmap = 'Reds')\n",
    "        sm.set_array(prediction_df['avg'])\n",
    "        cbar = plt.colorbar(sm)\n",
    "        \n",
    "\n",
    "        # Save the figure\n",
    "        plt.savefig(FILE_PATH + 'DeforestPlot_' + col_name)\n",
    "\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d49eb846d9e9e33562e6444db983d5d3192f0621d82336681e003790fb98d6fc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
